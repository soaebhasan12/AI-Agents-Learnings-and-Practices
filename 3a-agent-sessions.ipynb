{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:20:48.889720Z","iopub.execute_input":"2025-11-19T06:20:48.890008Z","iopub.status.idle":"2025-11-19T06:20:48.894748Z","shell.execute_reply.started":"2025-11-19T06:20:48.889984Z","shell.execute_reply":"2025-11-19T06:20:48.893700Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# üöÄ Memory Management - Part 1 - Sessions\n\n**Welcome to Day 3 of the Kaggle 5-day Agents course!**\n\nIn this notebook, you'll learn:\n\n- ‚úÖ What sessions are and how to use them in your agent\n- ‚úÖ How to build *stateful* agents with sessions and events\n- ‚úÖ How to persist sessions in a database\n- ‚úÖ Context management practices such as context compaction\n- ‚úÖ Best practices for sharing session State","metadata":{}},{"cell_type":"markdown","source":"## ‚ÄºÔ∏è Please Read\n\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:20:48.898212Z","iopub.execute_input":"2025-11-19T06:20:48.898574Z","iopub.status.idle":"2025-11-19T06:20:49.094942Z","shell.execute_reply.started":"2025-11-19T06:20:48.898550Z","shell.execute_reply":"2025-11-19T06:20:49.094021Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from typing import Any, Dict\n\nfrom google.adk.agents import Agent, LlmAgent\nfrom google.adk.apps.app import App, EventsCompactionConfig\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.sessions import DatabaseSessionService\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.runners import Runner\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:20:49.096408Z","iopub.execute_input":"2025-11-19T06:20:49.096810Z","iopub.status.idle":"2025-11-19T06:21:35.338436Z","shell.execute_reply.started":"2025-11-19T06:20:49.096783Z","shell.execute_reply":"2025-11-19T06:21:35.337519Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 1.4: Helper functions\n\nHelper function that manages a complete conversation session, handling session\ncreation/retrieval, query processing, and response streaming. It supports\nboth single queries and multiple queries in sequence.\n\nExample:\n\n```\n>>> await run_session(runner, \"What is the capital of France?\", \"geography-session\")\n>>> await run_session(runner, [\"Hello!\", \"What's my name?\"], \"user-intro-session\")\n```\n\n\n**Simple bhasha mein:** Ye function aapko AI se baat karne ka ek complete system deta hai - chahe ek question ho ya multiple questions ek saath.","metadata":{}},{"cell_type":"code","source":"# 'async' ka matlab hai \"yeh function time lene wala kaam karega\"\n# Jaise: AI se baat karna, database se data lena - yeh sab time leta hai\n\nasync def run_session(  # 'async' = \"Yeh function rukega (await) nahi, background mein kaam karega\"\n    runner_instance: Runner,\n    user_queries: list[str] | str = None,  # User ke questions - ek ya multiple\n    session_name: str = \"default\",  # Conversation session ka naam\n):\n    print(f\"\\n ### Session: {session_name}\")\n\n    # Runner se app ka naam le rahe hain\n    app_name = runner_instance.app_name\n\n    # Naya session banate hain ya purana wala retrieve karte hain\n    try:\n        # 'await' = \"Ruko, session ban jaye tabhi aage badho\"\n        session = await session_service.create_session(\n            app_name=app_name, user_id=USER_ID, session_id=session_name\n        )\n    except:\n        # 'await' = \"Ruko, existing session mil jaye tabhi aage badho\"  \n        session = await session_service.get_session(\n            app_name=app_name, user_id=USER_ID, session_id=session_name\n        )\n\n    # Agar user ne koi questions diye hain toh process karte hain\n    if user_queries:\n        # Single question ko list mein convert karte hain\n        if type(user_queries) == str:\n            user_queries = [user_queries]\n\n        # Har question ko ek ke baad ek process karte hain\n        for query in user_queries:\n            print(f\"\\nUser > {query}\")\n\n            # Simple string ko ADK ke format mein convert karte hain\n            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n\n            # 'async for' = \"AI ka response real-time mein aata rahega, har chunk ke saath kaam karo\"\n            async for event in runner_instance.run_async(\n                user_id=USER_ID, session_id=session.id, new_message=query\n            ):\n                # Check karte hain kya response mein kuch valid content hai\n                if event.content and event.content.parts:\n                    # Empty ya \"None\" responses ko skip karte hain\n                    if (\n                        event.content.parts[0].text != \"None\"\n                        and event.content.parts[0].text\n                    ):\n                        print(f\"{MODEL_NAME} > \", event.content.parts[0].text)\n    else:\n        print(\"Koi questions nahi diye!\")\n\nprint(\"‚úÖ Helper functions define ho gayi hain.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:35.339316Z","iopub.execute_input":"2025-11-19T06:21:35.340560Z","iopub.status.idle":"2025-11-19T06:21:35.351027Z","shell.execute_reply.started":"2025-11-19T06:21:35.340534Z","shell.execute_reply":"2025-11-19T06:21:35.350010Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions define ho gayi hain.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### 1.5: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:35.353105Z","iopub.execute_input":"2025-11-19T06:21:35.353372Z","iopub.status.idle":"2025-11-19T06:21:35.371380Z","shell.execute_reply.started":"2025-11-19T06:21:35.353351Z","shell.execute_reply":"2025-11-19T06:21:35.370415Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"**ü§π Section 2: Session Management**\n\n### 2.1 The Problem\n\nAsal mein, LLMs (Large Language Models) **bilkul stateless hote hain**. Unhe sirf wohi cheez pata hoti hai jo aap current API call mein dete ho. Matlab, agar aap koi aisa agent banaye jisme context management na ho, toh woh har naye prompt ko bilkul naye sawal ki tarah treat karega - pichli baatcheet bhool jayega.\n\n**‚ùì Problem samjhein?** Sochiye aap kisi aise insaan se baat kar rahe ho jo har sentence ke baad sab kuch bhool jata hai. Bilkul waisi hi situation hai raw LLMs ke saath!\n\nADK mein hum iska solution dete hain:\n- `Sessions` ‚Üí **Short term memory** ke liye (current baatcheet yaad rahe)\n- `Memory` ‚Üí **Long term memory** ke liye (permanent yaadein)\n\nAgle notebook mein hum `Memory` par focus karenge.","metadata":{}},{"cell_type":"markdown","source":"**ü§π Section 2: Session Management**\n\n### 2.2 Session Kya Hai?\n\n#### **üì¶ Session**\n\nSession ek container hai jo ek continuous conversation ko store karta hai. Ye conversation history, tool interactions aur responses ko chronologically save karta hai. Har session specific user aur agent ke liye hota hai - dusre users ya agents ke saath share nahi hota.\n\nADK mein, **Session** do cheezon se banta hai:\n\n**üìù Session.Events**:\n- Ye conversation ke building blocks hain\n- **Examples:**\n  - *User Input*: User ka message (text, audio, image, etc.)\n  - *Agent Response*: Agent ka jawab\n  - *Tool Call*: Agent koi external tool use kare\n  - *Tool Output*: Tool se mila data jo agent aage use karega\n\n**{} Session.State**:\n- Ye agent ki \"scratchpad\" hai - temporary storage\n- Global `{key, value}` pairs jo pure conversation mein available rehti hain\n- Subagents aur tools sab ise access kar sakte hain","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/session-state-and-events.png\" width=\"320\" alt=\"Session state and events\">\n\n<!-- ```mermaid\ngraph TD\n    subgraph A[\"Agentic Application\"];\n        subgraph U[\"User\"]\n            subgraph S1[\"Session\"]\n                D1[\"Session.Events\"]\n                D2[\"Session.State\"]\n            end\n        end\n    end\n``` -->","metadata":{}},{"cell_type":"markdown","source":"**ü§π Section 2: Session Management**\n\n### 2.3 Sessions Kaise Manage Karein?\n\nEk agentic application mein multiple users ho sakte hain, aur har user ke multiple sessions ho sakte hain. Inhe manage karne ke liye ADK do cheezein provide karta hai:\n\n1. **`SessionService`**: Storage layer\n   - Sessions create karna, store karna, aur retrieve karna\n   - Different storage options (memory, database, cloud)\n\n2. **`Runner`**: Orchestration layer  \n   - User aur agent ke beech information flow manage karta hai\n   - Automatically conversation history maintain karta hai\n   - Peeche se context engineering handle karta hai\n\n**Simple analogy samjhein:**\n\n- **Session** = Ek notebook üìì\n- **Events** = Notebook ke andar likhe hue individual entries üìù\n- **SessionService** = Notebooks ko store karne wali filing cabinet üóÑÔ∏è\n- **Runner** = Conversation manage karne wala assistant ü§ñ","metadata":{}},{"cell_type":"markdown","source":"### 2.4 Implementing Our First Stateful Agent\n\nLet's build our first stateful agent, that can remember and have constructive conversations. \n\nADK offers different types of sessions suitable for different needs. As a start, we'll start with a simple Session Management option (`InMemorySessionService`):","metadata":{}},{"cell_type":"code","source":"# Step 0: Basic Setup - Identity Define Kar Rahe Hain\nAPP_NAME = \"default\"    # Humari Application ka naam\nUSER_ID = \"default\"     # User ki pehchaan  \nSESSION = \"default\"     # Conversation session\n\nMODEL_NAME = \"gemini-2.5-flash-lite\"  # Kaunsi AI model use karenge\n\n# Step 1: LLM Agent Banayein\nroot_agent = Agent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"A text chatbot\",  # Ye agent kya kaam karega\n)\n\n# Step 2: Session Management Setup\n# InMemorySessionService - Conversations temporary RAM mein store karega\nsession_service = InMemorySessionService()\n\n# Step 3: Runner Banayein (Orchestration Layer)\n# Ye saari cheezein connect karega aur manage karega\nrunner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"‚úÖ Stateful agent taiyar hai!\")\nprint(f\"   - Application: {APP_NAME}\")\nprint(f\"   - User: {USER_ID}\")\nprint(f\"   - Storage Type: {session_service.__class__.__name__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:35.372313Z","iopub.execute_input":"2025-11-19T06:21:35.372616Z","iopub.status.idle":"2025-11-19T06:21:35.389939Z","shell.execute_reply.started":"2025-11-19T06:21:35.372593Z","shell.execute_reply":"2025-11-19T06:21:35.389034Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Stateful agent taiyar hai!\n   - Application: default\n   - User: default\n   - Storage Type: InMemorySessionService\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### 2.5 Testing Our Stateful Agent\n\nNow let's see the magic of sessions in action!","metadata":{}},{"cell_type":"code","source":"# Run a conversation with two queries in the same session\n# Notice: Both queries are part of the SAME session, so context is maintained\nawait run_session(\n    runner,\n    [\n        \"Hi, I am Sam! What is the capital of United States?\",\n        \"Hello! What is my name?\",  # This time, the agent should remember!\n    ],\n    \"stateful-agentic-session\",\n)","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:35.390867Z","iopub.execute_input":"2025-11-19T06:21:35.391095Z","iopub.status.idle":"2025-11-19T06:21:36.801986Z","shell.execute_reply.started":"2025-11-19T06:21:35.391075Z","shell.execute_reply":"2025-11-19T06:21:36.801172Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: stateful-agentic-session\n\nUser > Hi, I am Sam! What is the capital of United States?\ngemini-2.5-flash-lite >  Hi Sam! The capital of the United States is Washington, D.C.\n\nUser > Hello! What is my name?\ngemini-2.5-flash-lite >  Your name is Sam!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"üéâ **Success!** The agent remembered your name because both queries were part of the same session. The Runner automatically maintained the conversation history.\n\nBut there's a catch: `InMemorySessionService` is temporary. **Once the application stops, all conversation history is lost.** \n","metadata":{}},{"cell_type":"markdown","source":"### üõë (Optional) 2.6 Testing Agent's forgetfulness\n\n> To verify that the agent forgets the conversation, **restart the kernel**. Then, **run ALL the previous cells in this notebook EXCEPT the `run_session` in 2.5.**\n> \n> Now run the cell below. You'll see that the agent doesn't remember anything from the previous conversation.","metadata":{}},{"cell_type":"code","source":"# Run this cell after restarting the kernel. All this history will be gone...\nawait run_session(\n    runner,\n    [\"What did I ask you about earlier?\", \"And remind me, what's my name?\"],\n    \"stateful-agentic-session\",\n)  # Note, we are using same session name","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:36.802848Z","iopub.execute_input":"2025-11-19T06:21:36.803057Z","iopub.status.idle":"2025-11-19T06:21:37.563876Z","shell.execute_reply.started":"2025-11-19T06:21:36.803041Z","shell.execute_reply":"2025-11-19T06:21:37.562975Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: stateful-agentic-session\n\nUser > What did I ask you about earlier?\ngemini-2.5-flash-lite >  You asked me about the capital of the United States.\n\nUser > And remind me, what's my name?\ngemini-2.5-flash-lite >  Your name is Sam!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### The Problem\n\nSession information is not persistent (i.e., meaningful conversations are lost). While this is advantageous in testing environments, **in the real world, a user should be able to refer from past and resume conversations.** To achieve this, we must persist information. ","metadata":{}},{"cell_type":"markdown","source":"---\n## üìà Section 3: Persistent Sessions with `DatabaseSessionService`\n\nWhile `InMemorySessionService` is great for prototyping, real-world applications need conversations to survive restarts, crashes, and deployments. Let's level up to persistent storage!\n\n### 3.1 Choosing the Right SessionService\n\nADK provides different SessionService implementations for different needs:\n\n| Service | Use Case | Persistence | Best For |\n|---------|----------|-------------|----------|\n| **InMemorySessionService** | Development & Testing | ‚ùå Lost on restart | Quick prototypes |\n| **DatabaseSessionService** | Self-managed apps | ‚úÖ Survives restarts | Small to medium apps |\n| **Agent Engine Sessions** | Production on GCP | ‚úÖ Fully managed | Enterprise scale |\n","metadata":{}},{"cell_type":"markdown","source":"### 3.2 Implementing Persistent Sessions\n\nLet's upgrade to `DatabaseSessionService` using SQLite. This gives us persistence without needing a separate database server for this demo.\n\nLet's create a `chatbot_agent` capable of having a conversation with the user.","metadata":{}},{"cell_type":"code","source":"# Step 1: Create the same agent (notice we use LlmAgent this time)\nchatbot_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"A text chatbot with persistent memory\",\n)\n\n# Step 2: Switch to DatabaseSessionService\n# SQLite database will be created automatically\ndb_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\nsession_service = DatabaseSessionService(db_url=db_url)\n\n# Step 3: Create a new runner with persistent storage\nrunner = Runner(agent=chatbot_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"‚úÖ Upgraded to persistent sessions!\")\nprint(f\"   - Database: my_agent_data.db\")\nprint(f\"   - Sessions will survive restarts!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:37.564856Z","iopub.execute_input":"2025-11-19T06:21:37.565252Z","iopub.status.idle":"2025-11-19T06:21:37.657860Z","shell.execute_reply.started":"2025-11-19T06:21:37.565209Z","shell.execute_reply":"2025-11-19T06:21:37.656899Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Upgraded to persistent sessions!\n   - Database: my_agent_data.db\n   - Sessions will survive restarts!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### 3.3 Test Run 1: Verifying Persistence\n\nIn this first test run, we'll start a new conversation with the session ID `test-db-session-01`. We will first introduce our name as 'Sam' and then ask a question. In the second turn, we will ask the agent for our name.\n\nSince we are using `DatabaseSessionService`, the agent should remember the name.\n\nAfter the conversation, we'll inspect the `my_agent_data.db` SQLite database directly to see how the conversation `events` (the user queries and model responses) are stored.\n","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner,\n    [\"Hi, I am Sam! What is the capital of the United States?\", \"Hello! What is my name?\"],\n    \"test-db-session-01\",\n)","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:37.658663Z","iopub.execute_input":"2025-11-19T06:21:37.658924Z","iopub.status.idle":"2025-11-19T06:21:38.764284Z","shell.execute_reply.started":"2025-11-19T06:21:37.658904Z","shell.execute_reply":"2025-11-19T06:21:38.763209Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: test-db-session-01\n\nUser > Hi, I am Sam! What is the capital of the United States?\ngemini-2.5-flash-lite >  Hello Sam! The capital of the United States is Washington, D.C.\n\nUser > Hello! What is my name?\ngemini-2.5-flash-lite >  Your name is Sam.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### üõë (Optional) 3.4 Test Run 2: Resuming a Conversation\n\n> ‚ÄºÔ∏è Now, let's repeat the test again, but this time, **let's stop this Kaggle Notebook's kernel and restart it again.**\n>\n> 1. Run all the previous cells in the notebook, **EXCEPT** the previous Section 3.3 (`run_session` cell).\n>\n> 2. Now, run the below cell with the **same session ID** (`test-db-session-01`).\n\nWe will ask a new question and then ask for our name again. **Because the session is loaded from the database, the agent should still remember** that our name is 'Sam' from the first test run. This demonstrates the power of persistent sessions.\n","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner,\n    [\"What is the capital of India?\", \"Hello! What is my name?\"],\n    \"test-db-session-01\",\n)","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:38.765137Z","iopub.execute_input":"2025-11-19T06:21:38.765427Z","iopub.status.idle":"2025-11-19T06:21:39.370051Z","shell.execute_reply.started":"2025-11-19T06:21:38.765398Z","shell.execute_reply":"2025-11-19T06:21:39.368984Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: test-db-session-01\n\nUser > What is the capital of India?\ngemini-2.5-flash-lite >  The capital of India is New Delhi.\n\nUser > Hello! What is my name?\ngemini-2.5-flash-lite >  Your name is Sam.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### 3.5 Let's verify that the session data is isolated\n\nAs mentioned earlier, a session is private conversation between an Agent and a User (i.e., two sessions do not share information). Let's run our `run_session` with a different session name `test-db-session-02` to confirm this.\n","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner, [\"Hello! What is my name?\"], \"test-db-session-02\"\n)  # Note, we are using new session name","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:39.371192Z","iopub.execute_input":"2025-11-19T06:21:39.371532Z","iopub.status.idle":"2025-11-19T06:21:39.801702Z","shell.execute_reply.started":"2025-11-19T06:21:39.371502Z","shell.execute_reply":"2025-11-19T06:21:39.800792Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: test-db-session-02\n\nUser > Hello! What is my name?\ngemini-2.5-flash-lite >  I do not have access to your personal information, including your name. I am a language model and do not have the ability to store or retrieve personal data about users.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### 3.6 How are the events stored in the Database?\n\nSince we are using a sqlite DB to store information, let's have a quick peek to see how information is stored.","metadata":{}},{"cell_type":"code","source":"import sqlite3\n\ndef check_data_in_db():\n    with sqlite3.connect(\"my_agent_data.db\") as connection:\n        cursor = connection.cursor()\n        result = cursor.execute(\n            \"select app_name, session_id, author, content from events\"\n        )\n        print([_[0] for _ in result.description])\n        for each in result.fetchall():\n            print(each)\n\n\ncheck_data_in_db()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:39.802581Z","iopub.execute_input":"2025-11-19T06:21:39.802880Z","iopub.status.idle":"2025-11-19T06:21:39.809180Z","shell.execute_reply.started":"2025-11-19T06:21:39.802851Z","shell.execute_reply":"2025-11-19T06:21:39.808406Z"}},"outputs":[{"name":"stdout","text":"['app_name', 'session_id', 'author', 'content']\n('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hi, I am Sam! What is the capital of the United States?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Hello Sam! The capital of the United States is Washington, D.C.\"}], \"role\": \"model\"}')\n('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Sam.\"}], \"role\": \"model\"}')\n('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"What is the capital of India?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"The capital of India is New Delhi.\"}], \"role\": \"model\"}')\n('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Sam.\"}], \"role\": \"model\"}')\n('default', 'test-db-session-02', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-02', 'text_chat_bot', '{\"parts\": [{\"text\": \"I do not have access to your personal information, including your name. I am a language model and do not have the ability to store or retrieve personal data about users.\"}], \"role\": \"model\"}')\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"---\n## ‚è≥ Section 4: Context Compaction\n\nAs you can see, all the events are stored in full in the session Database, and this quickly adds up. For a long, complex task, this list of events can become very large, leading to slower performance and higher costs.\n\nBut what if we could automatically summarize the past? Let's use ADK's **Context Compaction** feature to see **how to automatically reduce the context that's stored in the Session.**","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/context-compaction.png\" width=\"1400\" alt=\"Context compaction\">","metadata":{}},{"cell_type":"markdown","source":"### **Section 4.1: Agent ke liye App Banayein**\n\nHum Section 3.2 mein banaye hue `chatbot_agent` ko hi use karenge.\n\nPehla step hai ek `App` object banana. Humein iska naam dena hoga aur apna `chatbot_agent` pass karna hoga.\n\nSaath hi, hum Context Compaction ke liye ek naya config banayenge. Ye **`EventsCompactionConfig`** do important cheezein define karta hai:\n\n- **`compaction_interval`**: Runner ko batata hai ki har `n` conversations ke baad history compact kare\n- **`overlap_size`**: Overlap ke liye pichli kitni conversations retain karni hain\n\nLast mein, hum ye app Runner ko provide karenge.\n\n**Simple bhasha mein:**\n- **App** = Ek wrapper jo agent ko additional features deta hai\n- **Context Compaction** = Purani conversations ko summarize karke memory save karna\n- **Compaction Interval** = Kitni baatcheet ke baad summarize kare\n- **Overlap** = Kuch purani details retain rakhna taaki context maintain ho","metadata":{}},{"cell_type":"code","source":"# Naya App Banayein - Events Compaction Ke Saath\nresearch_app_compacting = App(\n    name=\"research_app_compacting\",\n    root_agent=chatbot_agent,  # Wohi agent use kar rahe hain\n    # Yeh Naya Feature Hai!\n    events_compaction_config=EventsCompactionConfig(\n        compaction_interval=3,  # Har 3 conversations ke baad compaction karega\n        overlap_size=1,  # 1 purani conversation context ke liye retain karega\n    ),\n)\n\n# Database Connection Setup (Same as Before)\ndb_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\nsession_service = DatabaseSessionService(db_url=db_url)\n\n# Naya Runner Banayein - Compact App Ke Saath\nresearch_runner_compacting = Runner(\n    app=research_app_compacting, \n    session_service=session_service\n)\n\nprint(\"‚úÖ Research App Upgrade Ho Gaya - Events Compaction Active!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:39.810156Z","iopub.execute_input":"2025-11-19T06:21:39.810518Z","iopub.status.idle":"2025-11-19T06:21:39.830560Z","shell.execute_reply.started":"2025-11-19T06:21:39.810497Z","shell.execute_reply":"2025-11-19T06:21:39.829574Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Research App Upgrade Ho Gaya - Events Compaction Active!\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_48/3420240245.py:6: UserWarning: [EXPERIMENTAL] EventsCompactionConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  events_compaction_config=EventsCompactionConfig(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### 4.2 Running the Demo\n\nNow, let's have a conversation that is long enough to trigger the compaction. When you run the cell below, the output will look like a normal conversation. However, because we configured our `App`, a compaction process will run silently in the background after the 3rd invocation.\n\nIn the next step, we'll prove that it happened.","metadata":{}},{"cell_type":"code","source":"# Turn 1\nawait run_session(\n    research_runner_compacting,\n    \"What is the latest news about AI in healthcare?\",\n    \"compaction_demo\",\n)\n\n# Turn 2\nawait run_session(\n    research_runner_compacting,\n    \"Are there any new developments in drug discovery?\",\n    \"compaction_demo\",\n)\n\n# Turn 3 - Compaction should trigger after this turn!\nawait run_session(\n    research_runner_compacting,\n    \"Tell me more about the second development you found.\",\n    \"compaction_demo\",\n)\n\n# Turn 4\nawait run_session(\n    research_runner_compacting,\n    \"Who are the main companies involved in that?\",\n    \"compaction_demo\",\n)","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:39.831595Z","iopub.execute_input":"2025-11-19T06:21:39.831857Z","iopub.status.idle":"2025-11-19T06:21:57.060719Z","shell.execute_reply.started":"2025-11-19T06:21:39.831838Z","shell.execute_reply":"2025-11-19T06:21:57.059752Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: compaction_demo\n\nUser > What is the latest news about AI in healthcare?\ngemini-2.5-flash-lite >  Here's a summary of the latest news and trends in AI in healthcare:\n\n**Key Areas of Advancement and News:**\n\n*   **Drug Discovery and Development:**\n    *   **Accelerated Discovery:** AI continues to be a game-changer here. Companies are using AI to identify potential drug candidates, predict their efficacy, and optimize clinical trial design, significantly shortening timelines and reducing costs.\n    *   **Personalized Medicine:** AI is analyzing vast datasets (genomic, proteomic, clinical) to identify personalized treatment plans for patients, especially in areas like oncology.\n    *   **Recent News Highlights:** Look for announcements from major pharmaceutical companies and biotech startups detailing AI-driven breakthroughs in identifying novel targets or developing new therapies for diseases like Alzheimer's, cancer, and infectious diseases.\n\n*   **Diagnostics and Medical Imaging:**\n    *   **Enhanced Accuracy:** AI algorithms are becoming increasingly sophisticated at analyzing medical images (X-rays, CT scans, MRIs, pathology slides) to detect abnormalities with high accuracy, often spotting subtle signs that human eyes might miss.\n    *   **Early Disease Detection:** This leads to earlier and more accurate diagnoses for conditions like cancer, diabetic retinopathy, and cardiovascular diseases.\n    *   **Radiology Workflow:** AI tools are being integrated to triage urgent cases, automate measurements, and improve the overall efficiency of radiology departments.\n    *   **Recent News Highlights:** Expect news about FDA approvals for new AI-powered diagnostic tools, partnerships between AI companies and major hospitals for image analysis, and research papers demonstrating AI's performance on specific diagnostic tasks.\n\n*   **Personalized Treatment and Patient Management:**\n    *   **Predictive Analytics:** AI models are being used to predict patient outcomes, identify those at high risk of complications or readmission, and optimize care pathways.\n    *   **Remote Patient Monitoring:** Wearable devices and AI are enabling continuous monitoring of patients outside of traditional healthcare settings, allowing for early intervention and better chronic disease management.\n    *   **Virtual Assistants and Chatbots:** AI-powered chatbots are being deployed to answer patient questions, schedule appointments, provide medication reminders, and offer mental health support.\n    *   **Recent News Highlights:** Companies are announcing new platforms for remote patient monitoring, updates on AI tools that personalize treatment recommendations based on patient data, and increased adoption of AI chatbots for patient engagement.\n\n*   **Operational Efficiency and Administrative Tasks:**\n    *   **Reducing Burnout:** AI is helping to automate many time-consuming administrative tasks, such as medical coding, documentation, prior authorization, and scheduling, freeing up healthcare professionals to focus on patient care.\n    *   **Supply Chain Optimization:** AI is being used to improve hospital supply chain management, predict demand, and reduce waste.\n    *   **Recent News Highlights:** Look for announcements from healthcare IT companies offering AI solutions for revenue cycle management, clinical documentation improvement, and administrative automation.\n\n*   **Ethical Considerations and Regulatory Landscape:**\n    *   **Bias in AI:** A significant ongoing discussion revolves around ensuring AI algorithms are fair and unbiased, especially in diverse patient populations.\n    *   **Data Privacy and Security:** Protecting sensitive patient data used to train and operate AI systems remains a top priority.\n    *   **Regulatory Approval:** The FDA and other regulatory bodies are actively developing frameworks for the approval and oversight of AI-powered medical devices and software.\n    *   **Recent News Highlights:** Discussions and white papers on AI ethics in healthcare, new guidelines from regulatory bodies, and research exploring methods to mitigate bias in AI algorithms are prevalent.\n\n**Where to Find the Latest News:**\n\n*   **Reputable Healthcare and Technology News Outlets:**\n    *   STAT News (especially their AI and Health sections)\n    *   Fierce Healthcare / Fierce Biotech\n    *   MobiHealthNews\n    *   Healthcare Dive\n    *   MedTech Dive\n    *   TechCrunch (covering health tech)\n    *   The Wall Street Journal / New York Times (business and technology sections)\n*   **Industry Publications and Journals:**\n    *   Nature Medicine\n    *   The Lancet\n    *   JAMA (Journal of the American Medical Association)\n    *   IEEE journals related to AI and medicine\n*   **Conferences and Events:** Major AI and healthcare conferences often have press releases and reports on new developments.\n*   **Company Press Releases:** Follow leading AI companies in healthcare and major pharmaceutical/biotech firms.\n\n**To get the absolute \"latest\" news, I recommend checking these sources regularly, as the field is moving incredibly fast!** Is there a specific area of AI in healthcare you're most interested in? That might help me narrow down the information further.\n\n ### Session: compaction_demo\n\nUser > Are there any new developments in drug discovery?\ngemini-2.5-flash-lite >  Yes, there are **constant and exciting new developments** in AI-driven drug discovery. It's one of the most dynamic areas where AI is making a significant impact. Here are some of the key trends and recent developments:\n\n**1. Generative AI for Novel Molecule Design:**\n\n*   **What it is:** Instead of just screening existing libraries, AI models (especially generative adversarial networks or GANs and diffusion models) are now being used to *design entirely new molecules* with specific desired properties. They can learn the \"rules\" of chemistry and generate novel structures that have a higher probability of being effective and safe.\n*   **Recent Developments:** Companies are announcing the discovery of novel drug candidates for a range of diseases using these generative approaches. This includes small molecules for oncology, antivirals, and even potential treatments for rare genetic disorders.\n\n**2. Enhanced Target Identification and Validation:**\n\n*   **What it is:** AI is becoming incredibly adept at sifting through massive biological datasets (genomics, proteomics, transcriptomics, clinical data) to identify novel disease targets or re-purpose existing ones. It can uncover complex relationships between genes, proteins, and disease pathways that humans might miss.\n*   **Recent Developments:** AI is being used to pinpoint specific protein targets involved in complex diseases like Alzheimer's, Parkinson's, and various autoimmune conditions. This helps focus research efforts on the most promising areas.\n\n**3. Predicting Drug Efficacy and Toxicity Early On:**\n\n*   **What it is:** AI models can predict how a drug candidate might behave *in vivo* (in a living organism) much earlier in the discovery process. This includes predicting its efficacy against a target, its absorption, distribution, metabolism, and excretion (ADME) properties, and its potential toxicity.\n*   **Recent Developments:** This \"in silico\" (computer-based) testing significantly reduces the need for costly and time-consuming wet lab experiments and animal testing in the early stages, accelerating the overall pipeline.\n\n**4. Optimizing Clinical Trial Design:**\n\n*   **What it is:** AI can analyze historical clinical trial data and real-world evidence to identify ideal patient populations, predict trial success rates, and even suggest optimal dosing regimens.\n*   **Recent Developments:** This can lead to more efficient and targeted clinical trials, increasing the likelihood of success and reducing the time it takes to bring a drug to market. AI can also help identify potential biomarkers for patient stratification.\n\n**5. Advancements in Protein Folding and Structure Prediction (like AlphaFold):**\n\n*   **What it is:** While not directly designing drugs, breakthroughs like DeepMind's AlphaFold have revolutionized our understanding of protein structures. Knowing a protein's 3D structure is crucial for designing drugs that can bind to it effectively.\n*   **Recent Developments:** The availability of vast, accurate protein structure databases powered by AI is accelerating the rational design of drugs that can interact precisely with disease-causing proteins.\n\n**Key Players and Areas to Watch:**\n\n*   **Biotech Startups:** Many nimble startups are built entirely around AI for drug discovery. Companies like **Recursion Pharmaceuticals, Insitro, Exscientia, Atomwise, and BenevolentAI** are consistently making headlines with their AI-driven pipelines.\n*   **Major Pharmaceutical Companies:** Large pharma is heavily investing in and acquiring AI capabilities. They are integrating AI tools into their existing R&D processes, often through partnerships.\n*   **Specific Therapeutic Areas:** Look for AI-driven progress in areas with high unmet needs, such as neurodegenerative diseases, rare diseases, oncology, and infectious diseases.\n\n**To find the very latest news:**\n\n*   **Follow the companies mentioned above.**\n*   **Read reports from venture capital firms** specializing in life sciences and AI.\n*   **Keep an eye on scientific journals** like *Nature*, *Science*, and specialized AI/biotech publications.\n*   **Check out recent FDA approvals** for novel drugs ‚Äì AI played a role in many of these discoveries, even if it's not always explicitly highlighted in the public announcement.\n\nThe field is moving so rapidly that specific drug candidates are being identified and advanced weekly. It's a truly transformative period for pharmaceutical R&D.\n\n ### Session: compaction_demo\n\nUser > Tell me more about the second development you found.\ngemini-2.5-flash-lite >  You're referring to the second development I mentioned: **Enhanced Target Identification and Validation using AI.** This is a critical step in the drug discovery process, and AI is significantly revolutionizing it.\n\nLet's break down what this means and why it's so important:\n\n**The Challenge of Target Identification:**\n\n*   **Complexity of Biology:** Our bodies are incredibly complex. Diseases often arise from intricate disruptions in numerous biological pathways involving many genes, proteins, and molecules.\n*   **Vast Data:** The sheer volume of biological and medical data generated today is overwhelming for human analysis. This includes genomic sequences, gene expression data, protein interactions, clinical trial results, electronic health records, and scientific literature.\n*   **Finding the \"Right Lever\":** To create an effective drug, you need to identify a specific biological molecule (a \"target,\" usually a protein) that, when acted upon by a drug, can correct the disease process without causing unacceptable side effects. Finding this precise \"lever\" is incredibly difficult.\n*   **Traditional Methods are Slow and Expensive:** Historically, target identification relied heavily on manual experimentation, hypothesis-driven research, and often serendipity, which could take years and significant investment.\n\n**How AI Enhances Target Identification and Validation:**\n\nAI, particularly machine learning and deep learning, excels at processing and finding patterns within massive, complex datasets. Here's how it's applied:\n\n1.  **Analyzing Multi-Omics Data:**\n    *   **Genomics:** AI can analyze entire genomes to identify genes associated with diseases, looking for mutations or variations linked to altered protein function.\n    *   **Transcriptomics (RNA):** AI can study which genes are \"turned on\" or \"off\" in diseased cells versus healthy cells, revealing genes that are over- or under-expressed and might be good targets.\n    *   **Proteomics (Proteins):** AI can analyze the types and amounts of proteins present, identifying proteins that are abnormally activated or inhibited in disease states.\n    *   **Metabolomics (Metabolites):** AI can study the small molecules involved in cellular processes, which can also be indicative of disease and potential drug targets.\n    *   **Integration:** The real power comes from AI's ability to integrate all these \"omics\" layers to paint a more holistic picture of the disease at a molecular level.\n\n2.  **Mining Scientific Literature and Databases:**\n    *   AI-powered natural language processing (NLP) can scan millions of research papers, patents, and clinical trial reports. It can extract relationships between genes, proteins, diseases, and existing drugs, identifying novel connections and hypotheses that human researchers might have missed.\n\n3.  **Network Biology and Systems Biology:**\n    *   AI can build complex models of biological networks (e.g., protein-protein interaction networks, gene regulatory networks). By analyzing these networks, AI can identify \"central\" nodes (proteins) that, if targeted, could have a significant impact on the entire system to restore balance.\n\n4.  **Predictive Modeling:**\n    *   AI can build predictive models that forecast the likelihood of a particular gene or protein being a viable drug target. These models consider various factors like the target's role in pathways, its \"druggability\" (how easy it is to design a drug for it), and its potential safety profile.\n\n5.  **Identifying Novel Disease Mechanisms:**\n    *   By uncovering unexpected patterns, AI can reveal entirely new ways diseases develop, leading to the identification of targets that were previously not considered.\n\n**Validation:**\n\nOnce potential targets are identified, AI also plays a role in their **validation**:\n\n*   **Predicting Target-Drug Interactions:** AI can predict how well potential drug molecules would bind to a newly identified target.\n*   **Simulating Biological Effects:** AI can simulate the downstream effects of modulating a specific target within a biological system.\n*   **Analyzing Real-World Evidence:** AI can analyze large datasets of patient data to see if genetic variations related to a target protein correlate with disease outcomes, further supporting its role.\n\n**Why This is a \"New Development\":**\n\nWhile the concept of identifying disease targets isn't new, the **scale, speed, and accuracy** at which AI enables this process are revolutionary. Before AI, this was largely a manual, often serendipitous, and highly inefficient process. Now, it's becoming a more systematic, data-driven, and accelerated endeavor. This is leading to a richer pipeline of potential drug candidates entering the discovery and development phases.\n\n ### Session: compaction_demo\n\nUser > Who are the main companies involved in that?\ngemini-2.5-flash-lite >  You're asking about the key players driving AI-powered target identification and validation. This is a rapidly evolving landscape, with a mix of established pharmaceutical giants, innovative biotech startups, and specialized AI companies.\n\nHere are some of the main categories of companies involved and prominent examples:\n\n**1. Dedicated AI Drug Discovery Platforms (Biotech Startups):**\n\nThese companies are built from the ground up with AI at their core, focusing on using advanced algorithms to identify novel targets and design drug candidates. They are often the most vocal about their AI capabilities in this space.\n\n*   **Recursion Pharmaceuticals:** A leader in using AI and machine learning on biological imaging data to identify new drug targets and understand disease biology. They have a vast wet lab that generates experimental data, which their AI platform then analyzes.\n*   **Insitro:** Founded by Daphne Koller, Insitro aims to create large, high-quality biological datasets and use machine learning to interpret them for target discovery and drug development. They focus on integrating genomics, cellular imaging, and other data types.\n*   **Exscientia:** Known for its capabilities in designing novel molecules and identifying targets. They have been very active in forming partnerships with major pharma companies.\n*   **BenevolentAI:** Uses its AI platform to mine vast amounts of data, including scientific literature and clinical trial information, to identify new therapeutic targets and potential drugs.\n*   **Atomwise:** Focuses on using deep learning for small molecule drug discovery, including identifying targets and predicting interactions.\n*   **Schr√∂dinger:** While traditionally known for its physics-based computational chemistry software, Schr√∂dinger has heavily invested in AI and machine learning to augment its platform for target identification and drug design.\n\n**2. Large Pharmaceutical Companies (Adopting and Integrating AI):**\n\nMajor pharmaceutical companies are not standing still. They are actively investing, partnering, and building their own internal AI capabilities for target identification and validation.\n\n*   **Pfizer:** Has been a significant investor and partner in AI-driven drug discovery. They've formed collaborations and are building internal expertise.\n*   **Novartis:** Has been very public about its commitment to AI and machine learning across its R&D pipeline, including target identification.\n*   **GSK (GlaxoSmithKline):** Has made substantial investments in AI, including partnerships and acquisitions, to accelerate drug discovery, particularly for new targets.\n*   **AstraZeneca:** Is actively using AI to analyze complex biological data and identify novel therapeutic targets.\n*   **Merck (MSD):** Engaged in various initiatives to leverage AI for identifying new drug targets and optimizing development.\n*   **Janssen (Johnson & Johnson):** Actively explores AI for target discovery, particularly in areas like neuroscience and oncology.\n\n**3. Technology and AI Companies (Providing Tools and Platforms):**\n\nSome tech giants and specialized AI firms provide foundational AI technologies or platforms that can be adapted for biological research and target identification.\n\n*   **Google (Alphabet) / DeepMind:** While DeepMind's AlphaFold is primarily for protein structure, their broader AI capabilities are relevant. Google Cloud also offers AI and ML tools that biotech companies can leverage.\n*   **Microsoft:** Through its Azure cloud platform and AI tools, Microsoft supports biotech and pharma companies in their data analysis and AI initiatives.\n*   **Nvidia:** Provides powerful GPUs and AI computing platforms that are essential for training complex biological AI models. They also have specific initiatives focused on healthcare and life sciences.\n\n**4. Specialized Data and Analytics Companies:**\n\nSome companies focus on curating and structuring biological data in ways that make it more accessible and useful for AI analysis.\n\n*   **Companies providing curated omics databases or platforms.**\n\n**Key Trends in Partnerships:**\n\nYou'll see a lot of activity in the form of **partnerships and collaborations** between:\n\n*   **AI Startups and Big Pharma:** Pharma companies license or acquire AI technologies from startups to accelerate their own pipelines.\n*   **AI Companies and Academic Institutions:** Collaborations to develop new AI methods or apply them to specific biological problems.\n\nThe companies leading the charge are those that can effectively **integrate cutting-edge AI algorithms with high-quality biological data and deep scientific expertise.** It's a multidisciplinary effort.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Section 4.3: Session History mein Compaction Verify Karna**\n\nUpar wali conversation normal lag rahi thi, lekin background mein history change ho gayi hai. Ye kaise prove karein?\n\nHum apne session ka `events` list inspect kar sakte hain. Compaction process **purane events ko delete nahi karta; unhe ek naye `Event` se replace kar deta hai jo summary contain karta hai.** Aao use dhundhte hain.\n\n**Simple Steps:**\n1. Session ki events list access karo\n2. Dekho kya koi aisa event hai jiska type \"summary\" ya \"compaction\" hai\n3. Us event ka content check karo - wahi compressed history hogi\n\n**Example:**\n```python\nsession = await session_service.get_session(...)\nfor event in session.events:\n    if \"summary\" in event.type:  # Ya koi similar identifier\n        print(\"Yeh dekho compressed history:\", event.content)\n```\n\nIsse pata chal jayega ki compaction actually hua hai ya nahi! üîç","metadata":{}},{"cell_type":"code","source":"# Get the final session state\nfinal_session = await session_service.get_session(\n    app_name=research_runner_compacting.app_name,\n    user_id=USER_ID,\n    session_id=\"compaction_demo\",\n)\n\nprint(\"--- Searching for Compaction Summary Event ---\")\nfound_summary = False\nfor event in final_session.events:\n    # Compaction events have a 'compaction' attribute\n    if event.actions and event.actions.compaction:\n        print(\"\\n‚úÖ SUCCESS! Found the Compaction Event:\")\n        print(f\"  Author: {event.author}\")\n        print(f\"\\n Compacted information: {event}\")\n        found_summary = True\n        break\n\nif not found_summary:\n    print(\n        \"\\n‚ùå No compaction event found. Try increasing the number of turns in the demo.\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:21:57.061724Z","iopub.execute_input":"2025-11-19T06:21:57.062032Z","iopub.status.idle":"2025-11-19T06:21:57.074832Z","shell.execute_reply.started":"2025-11-19T06:21:57.062004Z","shell.execute_reply":"2025-11-19T06:21:57.073962Z"}},"outputs":[{"name":"stdout","text":"--- Searching for Compaction Summary Event ---\n\n‚úÖ SUCCESS! Found the Compaction Event:\n  Author: user\n\n Compacted information: model_version=None content=None grounding_metadata=None partial=None turn_complete=None finish_reason=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None live_session_resumption_update=None input_transcription=None output_transcription=None avg_logprobs=None logprobs_result=None cache_metadata=None citation_metadata=None invocation_id='4fd77796-bd3c-4304-a56e-eeeb3b553d26' author='user' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction={'start_timestamp': 1763533299.880072, 'end_timestamp': 1763533307.478045, 'compacted_content': {'parts': [{'function_call': None, 'code_execution_result': None, 'executable_code': None, 'file_data': None, 'function_response': None, 'inline_data': None, 'text': 'The user asked for news about AI in healthcare, and the AI agent provided a comprehensive overview. The user then specifically inquired about developments in drug discovery, and the AI agent highlighted several key areas: generative AI for molecule design, enhanced target identification/validation, predicting efficacy/toxicity, optimizing clinical trials, and advancements in protein folding. The user then requested more detail on the second development, \"Enhanced Target Identification and Validation using AI.\"\\n\\nThe AI agent explained the challenges of traditional target identification (biological complexity, vast data, difficulty finding the right \"lever,\" slow and expensive methods) and then detailed how AI addresses these challenges:\\n\\n*   **Analyzing Multi-Omics Data:** AI integrates genomic, transcriptomic, proteomic, and metabolomic data to understand disease at a molecular level.\\n*   **Mining Scientific Literature:** AI uses NLP to scan research papers and identify novel connections.\\n*   **Network Biology:** AI models biological networks to identify central targets with system-wide impact.\\n*   **Predictive Modeling:** AI forecasts the likelihood of a molecule being a viable drug target.\\n*   **Identifying Novel Disease Mechanisms:** AI uncovers new ways diseases develop.\\n\\nThe AI agent also touched on AI\\'s role in **validation**, including predicting drug-target interactions, simulating biological effects, and analyzing real-world evidence. The core takeaway for this development is that AI allows for target identification with unprecedented **scale, speed, and accuracy**, transforming a previously inefficient process.\\n\\n**Unresolved Questions/Tasks:**\\n\\n*   None. The user\\'s questions have been directly addressed.', 'thought': None, 'thought_signature': None, 'video_metadata': None}], 'role': 'model'}}, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None) long_running_tool_ids=set() branch=None id='312ce828-5147-455d-93db-acc77ebe44cf' timestamp=1763533314.87792\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Section 4.4: Tumne Kya Achieve Kiya - Automatic Context Management\n\nTumne proof dhundh liya! Session history mein woh special summary `Event` ka milna hi compaction process ka result hai.\n\n**Tumne abhi kya dekha:**\n\n1. **Silent Operation**: Normal conversation chala, bahar se koi farak nahi dikha\n2. **Background Compaction**: `EventsCompactionConfig` ki wajah se ADK `Runner` automatically conversation length monitor kar raha tha. Threshold cross hote hi usne background mein summarization shuru kar di\n3. **Verified Result**: Session events check karke tumne LLM ka banaya hua summary dhundh liya. Ye summary ab puri lengthy history ki jagah use hoga\n\n**Ab is conversation ke aage ke sabhi turns mein,** agent ko puri history nahi, ye concise summary diya jayega. \n\n**Benefits:**\n- Cost bachta hai\n- Performance better hoti hai  \n- Agent important cheezon par focus kar pata hai","metadata":{}},{"cell_type":"markdown","source":"### Section 4.5: ADK mein other Context Engineering Options\n\n#### üëâ Custom Compaction\nIs example mein humne ADK ka default summarizer use kiya. Advanced use cases ke liye, tum apna khud ka `SlidingWindowCompactor` bana sakte ho aur use config mein pass kar sakte ho. Isse tum:\n- Summarization prompt customize kar sakte ho\n- Alag, specialized LLM use kar sakte ho\n\n#### üëâ Context Caching  \nADK **Context Caching** bhi provide karta hai - ye LLM ko diye jaane wale static instructions ke token size ko reduce karta hai by request data cache karke.\n\n**Simple Matlab:**\n- **Custom Compaction** = Apna tarika se summary banwana\n- **Context Caching** = Repeated instructions ko cache karke performance improve karna\n\n[Official Documentation](https://google.github.io/adk-docs/) mein aur details hai! üìö","metadata":{}},{"cell_type":"markdown","source":"### Problem: Cross-Session Information Sharing\n\nAb tak humne seekha:\n- **Context Compaction** ‚Üí Ek session ki history summarize karna\n- **Database Sessions** ‚Üí Ek session ko resume karna\n\n**Nayi Challenge:** Kuch important information ya preferences hum **multiple sessions mein share** karna chahte hain.\n\n**Example:**\n- User ka naam (\"Sam\")\n- Language preference (\"Hindi\") \n- Theme preference (\"Dark mode\")\n\n**Problem:** Pure session history share karna efficient nahi hai. Bas kuch key variables transfer karna better hai.\n\n**Solution:** ADK mein **Memory** feature use karenge jo cross-session data sharing enable karta hai! üöÄ","metadata":{}},{"cell_type":"markdown","source":"### Section 5: Session State ke Saath Kaam Karna\n\n### 5.1 Session State Manage karne ke liye Custom Tools Banayein\n\nAao manually session state manage karna seekhein custom tools ke through. Is example mein, hum ek **transferable characteristic** identify karenge - jaise user ka naam aur country - aur use save/retrieve karne ke liye tools banayenge.\n\n**Yeh Example Kyu Achha Hai?**\n\nUsername ek perfect example hai aisi information ka jo:\n- Ek baar introduce hoti hai lekin baar-baar reference hoti hai\n- Pure conversation mein persist karni chahiye\n- User-specific characteristic hai jo personalization improve karti hai\n\n**Yahan Demo ke Liye:** Hum do tools banayenge:\n1. User ka naam aur country store karne ke liye\n2. User ka naam aur country retrieve karne ke liye\n\n**Important Note:** Saare tools ko `ToolContext` object access kar sakte hain. Har information ke liye alag tools banane ki zaroorat nahi hai.","metadata":{}},{"cell_type":"code","source":"# Define scope levels for state keys (following best practices)\nUSER_NAME_SCOPE_LEVELS = (\"temp\", \"user\", \"app\")\n\n\n# This demonstrates how tools can write to session state using tool_context.\n# The 'user:' prefix indicates this is user-specific data.\ndef save_userinfo(\n    tool_context: ToolContext, user_name: str, country: str\n) -> Dict[str, Any]:\n    \"\"\"\n    Tool to record and save user name and country in session state.\n\n    Args:\n        user_name: The username to store in session state\n        country: The name of the user's country\n    \"\"\"\n    # Write to session state using the 'user:' prefix for user data\n    tool_context.state[\"user:name\"] = user_name\n    tool_context.state[\"user:country\"] = country\n\n    return {\"status\": \"success\"}\n\n\n# This demonstrates how tools can read from session state.\ndef retrieve_userinfo(tool_context: ToolContext) -> Dict[str, Any]:\n    \"\"\"\n    Tool to retrieve user name and country from session state.\n    \"\"\"\n    # Read from session state\n    user_name = tool_context.state.get(\"user:name\", \"Username not found\")\n    country = tool_context.state.get(\"user:country\", \"Country not found\")\n\n    return {\"status\": \"success\", \"user_name\": user_name, \"country\": country}\n\n\nprint(\"‚úÖ Tools created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:22:06.602536Z","iopub.execute_input":"2025-11-19T06:22:06.602842Z","iopub.status.idle":"2025-11-19T06:22:06.610511Z","shell.execute_reply.started":"2025-11-19T06:22:06.602820Z","shell.execute_reply":"2025-11-19T06:22:06.609382Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Tools created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**Key Concepts:**\n- Tools can access `tool_context.state` to read/write session state\n- Use descriptive key prefixes (`user:`, `app:`, `temp:`) for organization\n- State persists across conversation turns within the same session","metadata":{}},{"cell_type":"markdown","source":"### 5.2 Creating an Agent with Session State Tools\n\nNow let's create a new agent that has access to our session state management tools:","metadata":{}},{"cell_type":"code","source":"# Configuration\nAPP_NAME = \"default\"\nUSER_ID = \"default\"\nMODEL_NAME = \"gemini-2.5-flash-lite\"\n\n# Create an agent with session state tools\nroot_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"\"\"A text chatbot.\n    Tools for managing user context:\n    * To record username and country when provided use `save_userinfo` tool. \n    * To fetch username and country when required use `retrieve_userinfo` tool.\n    \"\"\",\n    tools=[save_userinfo, retrieve_userinfo],  # Provide the tools to the agent\n)\n\n# Set up session service and runner\nsession_service = InMemorySessionService()\nrunner = Runner(agent=root_agent, session_service=session_service, app_name=\"default\")\n\nprint(\"‚úÖ Agent with session state tools initialized!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:22:11.566422Z","iopub.execute_input":"2025-11-19T06:22:11.566779Z","iopub.status.idle":"2025-11-19T06:22:11.574174Z","shell.execute_reply.started":"2025-11-19T06:22:11.566751Z","shell.execute_reply":"2025-11-19T06:22:11.573181Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Agent with session state tools initialized!\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"### 5.3 Testing Session State in Action\n\nLet's test how the agent uses session state to remember information across conversation turns:","metadata":{}},{"cell_type":"code","source":"# Test conversation demonstrating session state\nawait run_session(\n    runner,\n    [\n        \"Hi there, how are you doing today? What is my name?\",  # Agent shouldn't know the name yet\n        \"My name is Sam. I'm from Poland.\",  # Provide name - agent should save it\n        \"What is my name? Which country am I from?\",  # Agent should recall from session state\n    ],\n    \"state-demo-session\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:22:14.615040Z","iopub.execute_input":"2025-11-19T06:22:14.615404Z","iopub.status.idle":"2025-11-19T06:23:16.122263Z","shell.execute_reply.started":"2025-11-19T06:22:14.615379Z","shell.execute_reply":"2025-11-19T06:23:16.121066Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: state-demo-session\n\nUser > Hi there, how are you doing today? What is my name?\ngemini-2.5-flash-lite >  Hello! I'm doing well, thank you for asking. I can't recall your name at the moment. Could you please tell me what it is?\n\nUser > My name is Sam. I'm from Poland.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"gemini-2.5-flash-lite >  It's nice to meet you, Sam! I'll remember that you're from Poland.\n\nUser > What is my name? Which country am I from?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"gemini-2.5-flash-lite >  Your name is Sam and you are from Poland.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### 5.4 Inspecting Session State\n\nLet's directly inspect the session state to see what's stored:","metadata":{}},{"cell_type":"code","source":"# Retrieve the session and inspect its state\nsession = await session_service.get_session(\n    app_name=APP_NAME, user_id=USER_ID, session_id=\"state-demo-session\"\n)\n\nprint(\"Session State Contents:\")\nprint(session.state)\nprint(\"\\nüîç Notice the 'user:name' and 'user:country' keys storing our data!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:23:16.123207Z","iopub.execute_input":"2025-11-19T06:23:16.123628Z","iopub.status.idle":"2025-11-19T06:23:16.129808Z","shell.execute_reply.started":"2025-11-19T06:23:16.123604Z","shell.execute_reply":"2025-11-19T06:23:16.128835Z"}},"outputs":[{"name":"stdout","text":"Session State Contents:\n{'user:name': 'Sam', 'user:country': 'Poland'}\n\nüîç Notice the 'user:name' and 'user:country' keys storing our data!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"### 5.5 Session State Isolation\n\nAs we've already seen, an important characteristic of session state is that it's isolated per session. Let's demonstrate this by starting a new session:","metadata":{}},{"cell_type":"code","source":"# Start a completely new session - the agent won't know our name\nawait run_session(\n    runner,\n    [\"Hi there, how are you doing today? What is my name?\"],\n    \"new-isolated-session\",\n)\n\n# Expected: The agent won't know the name because this is a different session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:23:28.533117Z","iopub.execute_input":"2025-11-19T06:23:28.534183Z","iopub.status.idle":"2025-11-19T06:23:28.832915Z","shell.execute_reply.started":"2025-11-19T06:23:28.534149Z","shell.execute_reply":"2025-11-19T06:23:28.831804Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: new-isolated-session\n\nUser > Hi there, how are you doing today? What is my name?\ngemini-2.5-flash-lite >  Hello! I'm doing great. I'm not sure what your name is, though. Can you tell me? \n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"### 5.6 Cross-Session State Sharing\n\nWhile sessions are isolated by default, you might notice something interesting. Let's check the state of our new session (`new-isolated-session`):","metadata":{}},{"cell_type":"code","source":"# Check the state of the new session\nsession = await session_service.get_session(\n    app_name=APP_NAME, user_id=USER_ID, session_id=\"new-isolated-session\"\n)\n\nprint(\"New Session State:\")\nprint(session.state)\n\n# Note: Depending on implementation, you might see shared state here.\n# This is where the distinction between session-specific and user-specific state becomes important.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:23:35.586032Z","iopub.execute_input":"2025-11-19T06:23:35.586350Z","iopub.status.idle":"2025-11-19T06:23:35.591805Z","shell.execute_reply.started":"2025-11-19T06:23:35.586327Z","shell.execute_reply":"2025-11-19T06:23:35.590855Z"}},"outputs":[{"name":"stdout","text":"New Session State:\n{'user:name': 'Sam', 'user:country': 'Poland'}\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"---\n\n## üßπ Cleanup","metadata":{}},{"cell_type":"code","source":"# Clean up any existing database to start fresh (if Notebook is restarted)\nimport os\n\nif os.path.exists(\"my_agent_data.db\"):\n    os.remove(\"my_agent_data.db\")\nprint(\"‚úÖ Cleaned up old database files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T06:23:39.196193Z","iopub.execute_input":"2025-11-19T06:23:39.196951Z","iopub.status.idle":"2025-11-19T06:23:39.201992Z","shell.execute_reply.started":"2025-11-19T06:23:39.196918Z","shell.execute_reply":"2025-11-19T06:23:39.200963Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Cleaned up old database files\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"---\n## üìä Summary\n\nüéâ Congratulations! You've learned the fundamentals of building stateful AI agents:\n\n- ‚úÖ **Context Engineering** - You understand how to assemble context for LLMs using Context Compaction\n- ‚úÖ **Sessions & Events** - You can maintain conversation history across multiple turns\n- ‚úÖ **Persistent Storage** - You know how to make conversations survive restarts\n- ‚úÖ **Session State** - You can track structured data during conversations\n- ‚úÖ **Manual State Management** - You've experienced both the power and limitations of manual approaches\n- ‚úÖ **Production Considerations** - You're ready to handle real-world challenges\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You did it üéâ\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [ADK Documentation](https://google.github.io/adk-docs/)\n- [ADK Sessions](https://google.github.io/adk-docs/)\n- [ADK Session-State](https://medium.com/google-cloud/2-minute-adk-manage-context-efficiently-with-artifacts-6fcc6683d274)\n- [ADK Session Compaction](https://google.github.io/adk-docs/context/compaction/#define-compactor)\n\n### üéØ Next Steps - Long Term Memory Systems (Part 2)\n\n#### Why do we need memory?\nIn this notebook, we manually identified a couple characteristic (username and country) and built tools to manage it. But real conversations involve hundreds of such characteristics:\n- User preferences and habits\n- Past interactions and their outcomes\n- Domain knowledge and expertise levels\n- Communication styles and patterns\n- Contextual relationships between topics\n\n**The Memory System in ADK automates this entire process**, making it a valuable asset for building truly Context-Aware Agents that can accommodate any user's current and future needs.\n\nIn the next notebook (Part 2: Memory Management), you'll learn how to:\n- Enable automatic memory extraction from conversations\n- Build agents that learn and adapt over time\n- Create truly personalized experiences at scale\n- Manage long-term knowledge across sessions\n\nReady to transform your manual state management into an intelligent, automated Memory system? Let's continue to Part 2!","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Sampath M](https://www.linkedin.com/in/msampathkumar/) |","metadata":{}}]}