{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üöÄ Original Book Link: https://www.kaggle.com/code/kaggle5daysofai/day-1b-agent-architectures","metadata":{}},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:12:24.327948Z","iopub.execute_input":"2025-11-17T16:12:24.328369Z","iopub.status.idle":"2025-11-17T16:12:24.398355Z","shell.execute_reply.started":"2025-11-17T16:12:24.328337Z","shell.execute_reply":"2025-11-17T16:12:24.396926Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:12:47.912583Z","iopub.execute_input":"2025-11-17T16:12:47.912901Z","iopub.status.idle":"2025-11-17T16:13:46.462480Z","shell.execute_reply.started":"2025-11-17T16:12:47.912878Z","shell.execute_reply":"2025-11-17T16:13:46.461417Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:16:30.792450Z","iopub.execute_input":"2025-11-17T16:16:30.794019Z","iopub.status.idle":"2025-11-17T16:16:30.799986Z","shell.execute_reply.started":"2025-11-17T16:16:30.793984Z","shell.execute_reply":"2025-11-17T16:16:30.798927Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:16:37.432763Z","iopub.execute_input":"2025-11-17T16:16:37.433087Z","iopub.status.idle":"2025-11-17T16:16:37.441241Z","shell.execute_reply.started":"2025-11-17T16:16:37.433064Z","shell.execute_reply":"2025-11-17T16:16:37.440072Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:17:32.172439Z","iopub.execute_input":"2025-11-17T16:17:32.172768Z","iopub.status.idle":"2025-11-17T16:17:32.179248Z","shell.execute_reply.started":"2025-11-17T16:17:32.172744Z","shell.execute_reply":"2025-11-17T16:17:32.178011Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:18:45.793023Z","iopub.execute_input":"2025-11-17T16:18:45.793388Z","iopub.status.idle":"2025-11-17T16:18:45.800616Z","shell.execute_reply.started":"2025-11-17T16:18:45.793360Z","shell.execute_reply":"2025-11-17T16:18:45.799328Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:20:58.912335Z","iopub.execute_input":"2025-11-17T16:20:58.913821Z","iopub.status.idle":"2025-11-17T16:21:09.252195Z","shell.execute_reply.started":"2025-11-17T16:20:58.913764Z","shell.execute_reply":"2025-11-17T16:21:09.250749Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are characterized by the development of more powerful quantum processors and new qubit technologies, alongside crucial breakthroughs in quantum error correction. These advancements are critical for building reliable quantum computers, with major industry players aiming to achieve quantum advantage in the near future.\n\nThe implications for Artificial Intelligence (AI) are profound:\n\n*   **Accelerated AI Training:** Quantum computing can drastically speed up the training of AI models, leading to faster learning and more sophisticated AI systems.\n*   **Solving Complex Problems:** AI powered by quantum computing can tackle intricate optimization, simulation, and modeling tasks that are currently beyond the capabilities of classical computers, impacting fields like drug discovery and materials science.\n*   **Enhanced Data Processing:** Quantum machine learning algorithms can process large datasets more efficiently, improving pattern recognition and AI accuracy.\n*   **Improved Autonomous Systems:** Faster and more accurate data processing can significantly enhance the performance and decision-making of autonomous systems.\n*   **Cybersecurity Advancements:** Quantum AI may lead to more sophisticated threat detection and encryption methods.\n\nWhile the field of Quantum AI is still developing, significant breakthroughs and market growth are expected in the next decade. However, widespread commercial adoption will likely depend on further advancements in hardware, algorithms, and the development of specialized talent, alongside the exploration of hybrid quantum-classical computing approaches.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:23:58.231846Z","iopub.execute_input":"2025-11-17T16:23:58.232180Z","iopub.status.idle":"2025-11-17T16:23:58.239338Z","shell.execute_reply.started":"2025-11-17T16:23:58.232156Z","shell.execute_reply":"2025-11-17T16:23:58.238297Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:29:02.651231Z","iopub.execute_input":"2025-11-17T16:29:02.652168Z","iopub.status.idle":"2025-11-17T16:29:02.659249Z","shell.execute_reply.started":"2025-11-17T16:29:02.652126Z","shell.execute_reply":"2025-11-17T16:29:02.658164Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:29:07.755539Z","iopub.execute_input":"2025-11-17T16:29:07.755860Z","iopub.status.idle":"2025-11-17T16:29:07.761654Z","shell.execute_reply.started":"2025-11-17T16:29:07.755837Z","shell.execute_reply":"2025-11-17T16:29:07.760527Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:29:41.311931Z","iopub.execute_input":"2025-11-17T16:29:41.313154Z","iopub.status.idle":"2025-11-17T16:29:41.320447Z","shell.execute_reply.started":"2025-11-17T16:29:41.313105Z","shell.execute_reply":"2025-11-17T16:29:41.318526Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:29:52.598965Z","iopub.execute_input":"2025-11-17T16:29:52.599860Z","iopub.status.idle":"2025-11-17T16:30:01.802730Z","shell.execute_reply.started":"2025-11-17T16:29:52.599825Z","shell.execute_reply":"2025-11-17T16:30:01.801501Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here's a blog outline about the benefits of multi-agent systems for software developers:\n\n## Headline: Unleash Your Code's Potential: How Multi-Agent Systems Will Revolutionize Your Development Workflow\n\n### Introduction Hook:\nImagine a team of intelligent, independent \"digital assistants\" working tirelessly behind the scenes of your software projects. Not just simple scripts, but agents capable of learning, adapting, and collaborating. This isn't science fiction; it's the exciting reality of Multi-Agent Systems (MAS), and they're poised to transform how you build software.\n\n### Main Sections:\n\n#### 1. Enhanced Problem Solving and Complexity Management\n*   **Decomposition of Complex Tasks:** Break down massive, daunting software challenges into smaller, manageable sub-problems, each handled by a specialized agent. This makes intricate systems far easier to design, build, and debug.\n*   **Distributed Intelligence & Robustness:** Instead of a single monolithic application, MAS distributes intelligence. If one agent encounters an issue, others can often compensate, leading to more resilient and fault-tolerant systems.\n*   **Emergent Behavior for Novel Solutions:** When agents interact, unexpected and often highly effective solutions can emerge. This can lead to creative breakthroughs and optimizations that a single developer might not have conceived.\n\n#### 2. Boosted Efficiency and Automation\n*   **Automated Workflow Orchestration:** Agents can manage and automate complex development processes, from code generation and testing to deployment and monitoring, freeing up developers for higher-level tasks.\n*   **Intelligent Resource Allocation:** Agents can dynamically monitor system performance and user needs, intelligently allocating resources to ensure optimal efficiency and responsiveness.\n*   **Proactive Bug Detection and Remediation:** Agents can continuously scan code for potential issues, identify bugs in real-time, and even suggest or implement fixes, significantly reducing development cycles.\n\n#### 3. Improved Collaboration and Scalability\n*   **Facilitating Human-Agent Collaboration:** MAS can act as intelligent collaborators for human developers, providing insights, suggestions, and handling repetitive tasks, enhancing team productivity.\n*   **Seamless Scalability:** As your application grows, so can your agent system. New agents can be added or existing ones modified to handle increased load and functionality without requiring a complete system overhaul.\n*   **Specialized Agent Roles:** You can create agents with highly specialized skills (e.g., a \"security auditor\" agent, a \"performance optimizer\" agent), allowing for targeted expertise within your development team.\n\n#### 4. Future-Proofing Your Development Practices\n*   **Adaptability to Evolving Requirements:** Agents can be designed to learn and adapt to changing user needs and technological landscapes, making your software more agile and future-proof.\n*   **Foundation for AI-Powered Applications:** MAS provides a natural framework for building sophisticated AI-driven applications, from chatbots and recommendation engines to complex simulations.\n*   **Openness to Innovation:** Embracing MAS opens the door to integrating cutting-edge AI research and techniques into your software development lifecycle, keeping you at the forefront of technological advancement.\n\n### Concluding Thought:\nThe era of the lone coder is evolving. By embracing Multi-Agent Systems, software developers can tap into a powerful paradigm that not only streamlines current workflows but also unlocks unprecedented levels of complexity management, efficiency, and innovation, paving the way for the intelligent software of tomorrow.\nWriterAgent > ## Unleash Your Code's Potential: How Multi-Agent Systems Will Revolutionize Your Development Workflow\n\nImagine a team of intelligent, independent \"digital assistants\" working tirelessly behind the scenes of your software projects. Not just simple scripts, but agents capable of learning, adapting, and collaborating. This isn't science fiction; it's the exciting reality of Multi-Agent Systems (MAS), and they're poised to transform how you build software.\n\nMAS empowers you to break down complex challenges into smaller, manageable sub-problems, each handled by a specialized agent. This distributed intelligence leads to more robust and fault-tolerant systems, where if one agent falters, others can compensate. The emergent behavior from agent interactions can even spark novel solutions and optimizations that a single developer might overlook.\n\nBeyond problem-solving, MAS offers a significant boost in efficiency. Agents can automate intricate development workflows, from code generation and testing to deployment and monitoring, freeing you for higher-level strategic tasks. They can intelligently allocate resources and proactively detect and even remediate bugs in real-time, drastically shortening development cycles.\n\nCollaboration and scalability also reach new heights. Agents can act as invaluable human-agent collaborators, offering insights and handling repetitive tasks. As your application grows, your agent system can scale seamlessly by adding specialized agents for roles like security auditing or performance optimization. By embracing MAS, you‚Äôre not just streamlining current practices; you‚Äôre building the foundation for adaptable, AI-powered applications and staying at the forefront of technological innovation. The future of software development is collaborative, intelligent, and agent-driven.\nEditorAgent > ## Unleash Your Code's Potential: How Multi-Agent Systems Will Revolutionize Your Development Workflow\n\nImagine a team of intelligent, independent \"digital assistants\" working tirelessly behind the scenes of your software projects. These aren't just simple scripts; they are agents capable of learning, adapting, and collaborating. This is the exciting reality of Multi-Agent Systems (MAS), and they are poised to transform how you build software.\n\nMAS empowers you to break down complex challenges into smaller, manageable sub-problems, with each handled by a specialized agent. This distributed intelligence leads to more robust and fault-tolerant systems, where if one agent encounters an issue, others can often compensate. Furthermore, the emergent behavior from agent interactions can spark novel solutions and optimizations that a single developer might overlook.\n\nBeyond enhanced problem-solving, MAS offers a significant boost in efficiency. Agents can automate intricate development workflows, from code generation and testing to deployment and monitoring, freeing you to focus on higher-level strategic tasks. They can intelligently allocate resources and proactively detect, and even remediate, bugs in real-time, drastically shortening development cycles.\n\nCollaboration and scalability also reach new heights with MAS. Agents can act as invaluable human-agent collaborators, offering insights and handling repetitive tasks. As your application grows, your agent system can scale seamlessly by adding specialized agents for roles like security auditing or performance optimization. By embracing MAS, you‚Äôre not just streamlining current practices; you‚Äôre building the foundation for adaptable, AI-powered applications and staying at the forefront of technological innovation. The future of software development is collaborative, intelligent, and agent-driven.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:39:49.870694Z","iopub.execute_input":"2025-11-17T16:39:49.871042Z","iopub.status.idle":"2025-11-17T16:39:49.878448Z","shell.execute_reply.started":"2025-11-17T16:39:49.871018Z","shell.execute_reply":"2025-11-17T16:39:49.876950Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:40:10.462335Z","iopub.execute_input":"2025-11-17T16:40:10.462683Z","iopub.status.idle":"2025-11-17T16:40:10.470472Z","shell.execute_reply.started":"2025-11-17T16:40:10.462659Z","shell.execute_reply":"2025-11-17T16:40:10.468879Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:40:14.350570Z","iopub.execute_input":"2025-11-17T16:40:14.350893Z","iopub.status.idle":"2025-11-17T16:40:14.358486Z","shell.execute_reply.started":"2025-11-17T16:40:14.350869Z","shell.execute_reply":"2025-11-17T16:40:14.357560Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:40:20.735152Z","iopub.execute_input":"2025-11-17T16:40:20.736115Z","iopub.status.idle":"2025-11-17T16:40:20.742451Z","shell.execute_reply.started":"2025-11-17T16:40:20.736064Z","shell.execute_reply":"2025-11-17T16:40:20.741082Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:43:12.051076Z","iopub.execute_input":"2025-11-17T16:43:12.051972Z","iopub.status.idle":"2025-11-17T16:43:12.058181Z","shell.execute_reply.started":"2025-11-17T16:43:12.051943Z","shell.execute_reply":"2025-11-17T16:43:12.056833Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:43:23.955165Z","iopub.execute_input":"2025-11-17T16:43:23.955543Z","iopub.status.idle":"2025-11-17T16:43:30.349082Z","shell.execute_reply.started":"2025-11-17T16:43:23.955516Z","shell.execute_reply":"2025-11-17T16:43:30.347656Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nFinanceResearcher > This report summarizes key trends in technology, health, and finance for 2025.\n\n**Technology:**\nThe democratization of AI is a major trend, with AI adoption rapidly increasing across industries and becoming accessible to smaller enterprises. Agentic AI, which allows AI systems to plan and execute multi-step tasks autonomously, is also emerging. Further advancements include AI-native development platforms and AI supercomputing platforms, focusing on secure and scalable AI infrastructure.\n\n**Health:**\nFocus on gut health and probiotics is a significant trend, with consumers prioritizing digestive wellness. Telehealth continues to grow, driven by demand for convenience and accessibility. AI is also beginning to play a larger role in healthcare, from early disease detection to personalized medicine.\n\n**Finance:**\nAI integration is transforming financial services, from operational efficiency to personalized customer experiences. Lowering interest rates are expected, potentially easing strain on consumers and influencing investment strategies. The tokenization of real assets and the rise of decentralized autonomous banking systems are also shaping the future of finance, though these are longer-term developments.\n\n**Market Implications:**\nThese trends indicate a shift towards more intelligent, automated, and personalized services across all sectors. Companies that embrace AI and digital transformation will likely gain a competitive advantage, while those slower to adapt may face challenges. Consumer behavior is increasingly influenced by convenience, personalization, and a growing awareness of health and financial well-being.\n\n**Future Outlook:**\nThe future will see a deeper integration of AI, enabling more sophisticated autonomous systems. Digital transformation will continue to be crucial for market competitiveness. In health, a more proactive and personalized approach to wellness, driven by technology, is expected. In finance, evolving regulatory landscapes and emerging technologies like blockchain will likely lead to more diversified and potentially decentralized financial ecosystems.\nTechResearcher > **Key AI/ML Trends and Their Impact:**\n\nThree significant AI/ML trends shaping the landscape in 2025 are:\n\n1.  **Generative AI and Multimodal Models:** This trend focuses on AI's ability to create diverse content (text, images, audio, video) and understand multiple data types simultaneously. Major players like **Google (Gemini, Imagen, Veo)**, **OpenAI**, and **Stability AI** are leading this development. The impact is transformative, enhancing creativity, personalizing customer experiences, and accelerating content creation across industries.\n\n2.  **Agentic AI and Multi-Agent Systems:** AI is increasingly capable of autonomous decision-making and complex problem-solving. Companies like **Google** and startups in the AI space are developing these advanced systems. This trend will revolutionize fields such as logistics, autonomous driving, and complex operational management by enabling more sophisticated automation and decision-making.\n\n3.  **Explainable AI (XAI):** As AI becomes more integrated into critical sectors, there's a growing demand for transparency and trust. XAI aims to make AI decision-making understandable, which is crucial for regulated industries like **finance** and **healthcare**. Companies like **Google** are investing in ethical AI practices. The impact is increased trust, regulatory compliance, and broader adoption of AI in sensitive applications.\n\n**Main Companies Involved:**\n**Google** is a dominant force across these trends, with offerings like Gemini, Vertex AI, and DeepMind. Other key players include **OpenAI**, **Microsoft**, **NVIDIA** (providing essential hardware), **Amazon**, **Meta**, and specialized AI firms like **Stability AI** and **Synthesia**.\n\n**Potential Impact:**\nThese trends collectively promise significant advancements in productivity, efficiency, and innovation across nearly all sectors. They are driving digital transformation, enabling smarter decision-making, and creating new possibilities for human-AI collaboration. However, they also necessitate careful consideration of ethical implications, data privacy, and workforce adaptation.\nHealthResearcher > **Medical Breakthroughs:**\n\n1.  **Gene Therapy Advancements:** This involves introducing genetic material into cells to treat diseases. It's already used for certain blindness cases and holds promise for heart disease, cystic fibrosis, and hemophilia.\n2.  **AI in Diagnostics and Treatment:** AI is revolutionizing healthcare with improved detection for heart conditions, enhanced mammography accuracy, and repurposing existing medications for new treatments. AI is also improving Parkinson's treatment.\n3.  **At-Home Diagnostic Tests:** Rapid combination tests for COVID-19 and flu are now available over-the-counter, enabling quicker diagnosis and treatment initiation.\n\n**Technology Trends:**\n\n1.  **Generative AI:** Models like GPT-4o and Gemini are revolutionizing content creation, design, and problem-solving across industries, with applications in customer service, marketing, and product design.\n2.  **5G Rollout:** Widespread 5G implementation enhances data transmission capacity and supports advancements in autonomous vehicles, smart cities, and remote healthcare.\n3.  **Quantum Computing:** Advancements in quantum algorithms and hardware are accelerating breakthroughs in cybersecurity, cryptography, and drug discovery, with potential for early general-purpose quantum computers.\n\n**Financial Innovations:**\n\n1.  **Embedded Finance:** Financial services are seamlessly integrated into non-financial platforms, projected to reach $138 billion by 2026. This allows brands to offer banking, lending, and insurance directly within their services.\n2.  **AI-Powered Personalization:** AI is the driving force behind financial services, with the AI market in finance reaching $115.4 billion in 2025. It enhances personalization, risk assessment, and customer experience.\n3.  **Decentralized Finance (DeFi):** DeFi is maturing into a robust ecosystem, with improved security, scalability, and regulatory alignment. Decentralized exchanges offer deeper liquidity and lower fees.\n\n**Timelines:**\n\n*   **Gene Therapy:** Ongoing development, with current applications and broad promise for various diseases.\n*   **AI in Healthcare:** Rapid advancements are occurring now, with continued integration expected in the near future.\n*   **At-Home Diagnostic Tests:** Combination flu/COVID tests are available now, with multi-pathogen tests potentially arriving next year.\n*   **Generative AI:** Already in use, with significant growth and new applications emerging rapidly.\n*   **5G:** Widespread rollout is currently happening and will continue to expand infrastructure.\n*   **Quantum Computing:** Advancements are accelerating, with potential for general-purpose computers earlier than anticipated.\n*   **Embedded Finance:** Significant growth projected, reaching $138 billion by 2026.\n*   **AI in Finance:** Market already substantial, projected to double by 2029.\n*   **DeFi:** Maturing now, with ongoing improvements in security and scalability.\nAggregatorAgent > ## Executive Summary: 2025 Outlook - AI-Driven Transformation Across Tech, Health, and Finance\n\nThe convergence of **Artificial Intelligence (AI)** is the most dominant theme across technology, health, and finance for 2025. **Generative AI** and **Agentic AI** are rapidly evolving, promising enhanced creativity, personalized experiences, and sophisticated autonomous decision-making across all sectors. Key players like Google and OpenAI are spearheading these advancements.\n\nIn **healthcare**, AI is revolutionizing diagnostics and treatment, augmenting human capabilities for earlier disease detection and personalized medicine. Alongside this, gene therapy continues its promising development, while accessible at-home diagnostic tests are empowering consumers.\n\nThe **financial sector** is experiencing a profound AI-driven transformation, enhancing personalization, operational efficiency, and risk assessment. Innovations like embedded finance and maturing DeFi ecosystems are reshaping how financial services are delivered and accessed.\n\nOverall, these interconnected trends point towards a future of **increased automation, hyper-personalization, and enhanced intelligence**. Companies embracing AI and digital transformation will lead, while ethical considerations and workforce adaptation remain critical. The underlying advancements in AI are not only driving efficiency but also enabling breakthroughs in health and creating more dynamic financial landscapes.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:47:12.711016Z","iopub.execute_input":"2025-11-17T16:47:12.711472Z","iopub.status.idle":"2025-11-17T16:47:12.718944Z","shell.execute_reply.started":"2025-11-17T16:47:12.711438Z","shell.execute_reply":"2025-11-17T16:47:12.717664Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:51:15.792360Z","iopub.execute_input":"2025-11-17T16:51:15.792718Z","iopub.status.idle":"2025-11-17T16:51:15.799807Z","shell.execute_reply.started":"2025-11-17T16:51:15.792693Z","shell.execute_reply":"2025-11-17T16:51:15.798364Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:52:36.214112Z","iopub.execute_input":"2025-11-17T16:52:36.214463Z","iopub.status.idle":"2025-11-17T16:52:36.224039Z","shell.execute_reply.started":"2025-11-17T16:52:36.214438Z","shell.execute_reply":"2025-11-17T16:52:36.222567Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:52:51.292405Z","iopub.execute_input":"2025-11-17T16:52:51.292734Z","iopub.status.idle":"2025-11-17T16:52:51.300024Z","shell.execute_reply.started":"2025-11-17T16:52:51.292708Z","shell.execute_reply":"2025-11-17T16:52:51.298804Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:54:06.538769Z","iopub.execute_input":"2025-11-17T16:54:06.539118Z","iopub.status.idle":"2025-11-17T16:54:06.545788Z","shell.execute_reply.started":"2025-11-17T16:54:06.539094Z","shell.execute_reply":"2025-11-17T16:54:06.544295Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:54:40.056947Z","iopub.execute_input":"2025-11-17T16:54:40.057409Z","iopub.status.idle":"2025-11-17T16:54:48.732244Z","shell.execute_reply.started":"2025-11-17T16:54:40.057382Z","shell.execute_reply":"2025-11-17T16:54:48.730737Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > The salty spray kissed Elias‚Äôs weathered face as he climbed the spiral stairs, the lamp already a comforting beacon against the encroaching dusk. Tonight, the sea whispered secrets, and Elias, in his solitude, felt more attuned than ever. He was polishing the Fresnel lens when a glint caught his eye, nestled amongst the discarded ropes and sea-worn buoys in the keeper‚Äôs quarters. It was a rolled parchment, brittle with age, but strangely warm to the touch. Unfurling it, Elias gasped. Lines of shimmering, phosphorescent ink pulsed across the vellum, forming not a nautical chart he recognized, but a constellation of islands and currents he'd never seen. A single, glowing X marked a spot far out in the uncharted western sea. The lighthouse, his constant companion, seemed to hum a low, anticipatory note.\nCriticAgent > The story sets up an intriguing mystery, but could benefit from a bit more development.\n\n1.  **Character Depth:** Elias is currently a somewhat archetypal lonely lighthouse keeper. While his attunement to the sea is established, giving him a brief internal thought or memory related to *why* he's solitary, or what he yearns for, could make his discovery more impactful. Is he looking for something? Escaping something?\n2.  **Sensory Details of the Map:** The phosphorescent ink and glowing 'X' are excellent starting points. To heighten the mystery, describe the *feel* of the parchment beyond \"brittle with age\" and \"strangely warm.\" Does it have an unusual texture? A faint scent? What do the islands and currents look like beyond just being \"uncharted\"? Are there strange symbols or formations?\n3.  **Foreshadowing the \"Hum\":** The lighthouse humming is a nice touch of the uncanny. You could subtly foreshadow this earlier by describing Elias's familiarity with the lighthouse's sounds. Perhaps he notices a new, deeper resonance in its usual creaks and groans *before* he finds the map, making the hum feel like a confirmation or a response rather than a sudden event.\nRefinerAgent > The salty spray kissed Elias‚Äôs weathered face as he climbed the spiral stairs, the lamp already a comforting beacon against the encroaching dusk. Tonight, the sea whispered secrets, and Elias, in his solitude, felt more attuned than ever. He often found himself lost in memories out here, the rhythmic crash of waves a constant reminder of the life he‚Äôd left behind, a life he‚Äôd sought to escape, though the exact reasons now felt as foggy as the pre-dawn sea. He‚Äôd chosen this isolation, this quiet vigilance, but sometimes, in the deep hours, a hollow ache for connection would surface.\n\nHe was polishing the Fresnel lens, its multifaceted surface a dazzling eye in the fading light, when a glint caught his eye. It was nestled amongst the discarded ropes and sea-worn buoys in the keeper‚Äôs quarters. A faint scent, like dried kelp and ancient sea salt, drew him closer. It was a rolled parchment, brittle with age, but strangely warm to the touch, its surface feeling like cured leather, smooth yet textured. Unfurling it, Elias gasped.\n\nLines of shimmering, phosphorescent ink pulsed across the vellum, forming not a nautical chart he recognized, but a swirling, dreamlike constellation of islands. Some depicted serpentine coastlines with jagged peaks that seemed to writhe, while others were mere dots surrounded by currents that flowed in impossible, spiraling patterns. Strange, indecipherable symbols were etched along the borders. A single, glowing 'X', radiating a soft, cerulean light, marked a spot far out in the uncharted western sea.\n\nAs he traced the luminous lines with a trembling finger, Elias felt a deep vibration thrum through the stone floor beneath his feet. It was a resonance he knew intimately, the lighthouse‚Äôs familiar groans and sighs, but tonight it was different‚Äîdeeper, more resonant, as if the tower itself was awakening. It seemed to hum a low, anticipatory note, a response to the map‚Äôs silent, luminous call.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}